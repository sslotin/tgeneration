{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ввод как изменяемый параметр\n",
    "\n",
    "Картинки хороши тем, что они не дискретные и имеют хорошие градиенты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAw47smKaFwi"
   },
   "source": [
    "## DeepDream (июль 2015)\n",
    "\n",
    "Если двигать ввод в сторону улучшения какого-то класса, то изображение начнет изменяться так, чтобы сеть его воспринимало как.\n",
    "\n",
    "Сеть обучается расознавать разные объекты. Уже обученную можно использовать «наоборот»: изменять входное изображение так, чтобы оно, например, было больше похоже на фотографию котика (предсказанная вероятность нейрона максимизируется). \n",
    "\n",
    "Если каждый раз идти по этом градиенту маленьким шагами, то сгенерятся сюрреалистические и психоделические картинки. На них, обычно, очень много объектов нужного класса в самых неожиданных местах.\n",
    "\n",
    "Обучение происходит чисто через backprop, только вместо фиксированного входа и обучаемых весов происходит наоборот — вход можно оптимизировать, а веса остаются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "aprser.add_argument('image', help='Path to modified image.')\n",
    "aprser.add_argument('model', help='Path to trained inception model.')\n",
    "parser.add_argument('--target_label', default=0,\n",
    "                    help='Number of target label. Default is a cat.')\n",
    "\n",
    "parser.add_argument('--num_iterations', default=50)\n",
    "parser.add_argument('--learning_rate', default=0.01)\n",
    "\n",
    "parser.add_argument('--gif_duration', default=2)\n",
    "parser.add_argument('--gif_delay', default=1)\n",
    "parser.add_argument('--gif_filename', default='dream.gif')\n",
    "\n",
    "args = parser.parse_arguments()\n",
    "\n",
    "\n",
    "device = torch.device(args.device)\n",
    "\n",
    "img = torch.Tensor(load_img(args.image), trainable=True).to(device)\n",
    "model = load_model(args.model).to(device)\n",
    "\n",
    "target = torch.zeros(args.num_labels)\n",
    "target[args.target_label] = 1\n",
    "\n",
    "def make_gif(images):\n",
    "    pass\n",
    "\n",
    "def get_image(img):\n",
    "    return img.reshape(3, 140, 140).cpu().numpy()\n",
    "\n",
    "for _ in range(args.num_iterations):\n",
    "    probs = model.forward(img)\n",
    "    loss = F.crossentropy(probs, target)\n",
    "    loss.backward()\n",
    "\n",
    "    # Теперь интересная часть. На финальных стадиях лосс и так очень маленький.\n",
    "    # Значит, градиенты тоже будут маленькими.\n",
    "    # Отнормируем его так, чтобы делать шаги одинакового размера.\n",
    "    # Градиент теперь нам подсказывает направление, но не размер шага\n",
    "\n",
    "    lr_scaled = args.learning_rate / img.grad.data.cpu().numpy().abs().mean()\n",
    "    #                                ^        Офигенная строчка, да?        ^\n",
    "    img -= lr_scaled * img.grad.data\n",
    "\n",
    "    images += [get_image(img)]\n",
    "\n",
    "make_gif(images, args.gif_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Style Transfer (январь 2016)\n",
    "\n",
    "Как известно, фичи в сетях имеют. \n",
    "\n",
    "Автору до сих пор не до конца понятно, почему.\n",
    "\n",
    "Считается матрица Грама — в линейной алгебре это скалярные умножения. Это матрица показывают, как фичи коррелируют между собой.\n",
    "\n",
    "Важно: сеть уже обучена на чем-то. На имаджнете, например."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.data import Dataset, Dataloader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "aprser.add_argument('folder', help='Path to folder with images.')\n",
    "\n",
    "parser.add_argument('--num_iterations', default=50)\n",
    "parser.add_argument('--learning_rate', default=0.01)\n",
    "\n",
    "parser.add_argument('--gif_duration', default=2)\n",
    "parser.add_argument('--gif_delay', default=1)\n",
    "parser.add_argument('--gif_filename', default='dream.gif')\n",
    "\n",
    "parser.add_argument('--discriminator_iters', default='dream.gif')\n",
    "\n",
    "args = parser.parse_arguments()\n",
    "\n",
    "\n",
    "device = torch.device(args.device)\n",
    "\n",
    "img = torch.Tensor(load_img(args.image), trainable=True).to(device)\n",
    "model = load_model(args.model).to(device)\n",
    "\n",
    "target = torch.zeros(args.num_labels)\n",
    "target[args.target_label] = 1\n",
    "\n",
    "dataset = ImageFolder(args.folder)\n",
    "\n",
    "loader = Dataloader(dataset, args.batch_size)\n",
    "\n",
    "G = nn.Sequential(\n",
    "    nn.Linear(),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(),\n",
    "    nn.ReLU(),\n",
    "    Reshape(),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "D = nn.Sequential(\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.params(), lr=args.learning_rate)\n",
    "\n",
    "for epoch in range(args.num_epochs):\n",
    "    for i, real in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        noise = torch.randn(args.batch_size, args.noise_dim)\n",
    "        fake = model.forward(noise)\n",
    "\n",
    "        real_labels = torch.ones(args.batch_size)\n",
    "        fake_labels = torch.zeros(args.batch_size)\n",
    "\n",
    "        X = # concat images\n",
    "        Y = # concat labels\n",
    "\n",
    "        loss = F.crossentropy(D(X), Y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % args.sample_every == 0:\n",
    "            print('%d-%d: %.4f $.4f' % (epoch, i, loss_G.item(), loss_D.item()))\n",
    "            # save images that are in the batch\n",
    "    \n",
    "        # Кормить вместе однородные данные — быстрее\n",
    "\n",
    "        \n",
    "\n",
    "make_gif(images, args.gif_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial атаки\n",
    "\n",
    "![panda](images/panda.jpg)\n",
    "\n",
    "Оказывается, достаточно сдвинуть данные в сторону на совсем чуть-чуть, чтобы перевести её в другой класс по мнению классификатора.\n",
    "\n",
    "На самом деле, архитектуры нейросетей очень уязвимы к таким атакам.\n",
    "\n",
    "Можно IRL изготовить какие-нибудь аттрибуты одежды и заставить камеры наблюдения думать, что вы не вы.\n",
    "\n",
    "Для этого нужно иметь доступ к самой архитектуре.\n",
    "\n",
    "Достаточно изменить даже один пиксель.\n",
    "\n",
    "[мем про one hot boi]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "9_nst.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
