{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q3rZATlAX6U3"
   },
   "source": [
    "# Генеративные состязательные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "em7Ir5hmX6U7"
   },
   "source": [
    "https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py\n",
    "\n",
    "https://habr.com/post/332000/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PfTKnH2fX6U9"
   },
   "source": [
    "![gan](images/gan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UE8ZY68jj9G6"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gsj7xh1Gj0ER"
   },
   "source": [
    "https://www.youtube.com/watch?v=AJVyzd0rqdc — на 1:03:00 можно услышать, как Шмидхубер качает права на ганы. Впрочем, он прав."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GLTeTpf6X6VA"
   },
   "source": [
    "GAN-ы состоят из двух частей:\n",
    "\n",
    "1. Генератор (будем обозначать его $G$), который сэмплит случайные числа из какого-то определенного распределения (например, нормального) и генерируют из них объекты, которые идут на вход второй сети.\n",
    "\n",
    "2. Дискриминатор $D$, который получает на вход объекты из выборки и созданные генератором, и учится предсказывать вероятность того, что конкретный объект реальный (он выдает скаляр — число от 0 до 1).\n",
    "\n",
    "GAN-ы нужны для «обучения» распределения очень сложных данных (например, изображений), и применяются очень много где, но не в продакшене, а скорее в ресёрче, потому что их на данный момент очень трудно обучать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WsMKcliQX6VF"
   },
   "source": [
    "Аналогия: представьте двух людей — один пытается подделать произведения искусства, а второй пытается это распознать. Рано или поздно у нас в результате такой длящейся бесконечно долго игры получаются два очень полезных ресурса — генератор **новых** произведений искусства и распознаватель подделок — оба из которых можно применить где-нибудь ещё (а можно и просто наслаждаться синтетическим искусством)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dR3r059NX6VG"
   },
   "source": [
    "GAN — это такое прямое прохождение теста Тьюринга. Примерно это и мотивирует все их применения в генеративных моделях. Например, колоризацию «правильно» делать так: обучаем одну сеть, которая раскрашивает, а вторая — определяет качество раскраски. Генерация диалогов или перевода — точно так же, вместо языковой модели — две играющие друг против друга сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0Hblue4X6VJ"
   },
   "source": [
    "Все бы прекрасно, но у нас есть проблема — мы не знаем, как мерить качество GAN-ов и вообще всех генеративных моделей. Эта проблема ещё не решена. Ничего умнее мнения независимых сетей-классификаторов («inception score») или субъективных человеческих оценок не придумали. Пока что у нас вообще никаких способов оценить качество модели, кроме того, как посмотреть на данные раз в сколько-то эпох. Это всё заметно тормозит архитектурный поиск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AB02gwUQX6VL"
   },
   "source": [
    "* Unsupervised NMT\n",
    "* CycleGAN\n",
    "* Conditional GAN\n",
    "* InfoGAN\n",
    "* Морфинг\n",
    "* VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nw-1qFzuX6VO"
   },
   "source": [
    "# Код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8iAqLdhuX6VQ"
   },
   "source": [
    "В этой тетрадке мы будем научимся писать сети на чуть более низком уровне, потому что стандартный .fit() для наших целей недостаточно гибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sB535H-jX6VW"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "import numpy as np\n",
    "from mnist import X\n",
    "X = X.reshape(-1, 28, 28)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53EDGAlFX6Vd"
   },
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "batch_size = 64\n",
    "sample_interval = 50\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6GP_nJSX6Vi"
   },
   "source": [
    "Генератор сделаем полносвязным. Желающие могут написать через deconvolution-ы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zAD7bdQX6Vk"
   },
   "outputs": [],
   "source": [
    "G = Sequential([\n",
    "    Dense(256, input_dim=latent_dim),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dense(512),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dense(784),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Reshape((28, 28))\n",
    "])\n",
    "\n",
    "#G.compile()\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hq4e5FkFX6Vr"
   },
   "outputs": [],
   "source": [
    "D = Sequential([\n",
    "    Dense(512, input_dim=784),\n",
    "    LeakyReLU(),\n",
    "    Dense(256),\n",
    "    LeakyReLU(),\n",
    "    Dense(64),\n",
    "    LeakyReLU(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "D.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A2easzUmX6Vy"
   },
   "source": [
    "Теперь сольем их в одну модель, как делали с автоэнкодерами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9yrye4OPX6V0"
   },
   "outputs": [],
   "source": [
    "z = Input(shape=(latent_dim,))\n",
    "img = G(z)\n",
    "D.trainable = False # тут нам нужно отключить ему градиенты, чтобы при обучении всего GAN-а они не менялись\n",
    "validity = D(img)\n",
    "GAN = Model(z, validity)\n",
    "GAN.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8llczT1AX6V7"
   },
   "source": [
    "Самое содержательное это цикл обучения. Его нужно написать вручную — model.fit() не прокатит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFoEymF3X6V9"
   },
   "outputs": [],
   "source": [
    "# эпохи — это в смысле батчи\n",
    "for epoch in range(epochs):\n",
    "    # сначала обучим дискриминатор\n",
    "    real = X[np.random.randint(0, X.shape[0], batch_size)] # так можно посэмплить батч вручную\n",
    "    noise = np.random.randn((batch_size, latent_dim))\n",
    "    fake = G.predict(noise)\n",
    "    \n",
    "    d_loss_real = D.train_on_batch(real, np.ones((batch_size, 1)))\n",
    "    d_loss_fake = D.train_on_batch(fake, np.zeros((batch_size, 1)))\n",
    "    d_loss = np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # теперь обучаем генератор\n",
    "    noise = np.random.randn((batch_size, latent_dim))\n",
    "    g_loss = GAN.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "    print (\"%d, D loss: %f, G loss: %f\" % (epoch, d_loss[0], g_loss))\n",
    "\n",
    "    if epoch % sample_interval == 0:\n",
    "        # выводим то, что в батче\n",
    "        # дополнительных вычислений это не стоит\n",
    "        fake = fake.reshape(-1, 28, 28)\n",
    "        \n",
    "        fig, axs = plt.subplots(8, 8)\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                axs[i,j].imshow(gen_imgs[i*8 + j])\n",
    "                axs[i,j].axis('off')\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close() # не уверен, что это нужно; я это откуда-то скопировал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VxxGgTyYKQ2"
   },
   "source": [
    "# Клёвые применения\n",
    "\n",
    "**Морфинг**. VAE — это классно. Такой умных шум в скрытом состоянии делает его более равномерно распределенным и пригодным для морфинга, но в GAN-ах всё совсем хорошо: сеть училась генерировать вообще из всего нормального распределения, а значит, оно должно быть полностью покрыто, без дыр в принципе.\n",
    "\n",
    "**Генерация признаков**. Так же, как и с VAE, можно спокойно выделить «вектор голубых глаз» и пользоваться подобной арифметикой для генерации объектов с определенными свойствами. Иногда в датасете эти признаки как-то даются сверху, и это можно использовать для улучшения архитектуры: например, в MNIST-е можно явно передать one-hot вектор (9 нулей, 1 единичка), который будет помогать сети генерировать цифру с конкретно этим лейблом.\n",
    "\n",
    "**CycleGAN** / **Dual GAN**. Мы хотим «переводить» изображения из домена А в домен Б и наоборот. Обучим 4 сети — два генетатора и два дискриминатора. Первый будет принимать на вход изображения из А и перегонять в Б, второй — наоборот. Дискриминаторы будут, как обычно, пытаться отличать, какое изображение реальное, а какое — сгенерированное из другого домена. Лоссом перевода будет сумма из какого-нибудь reconstruction и дискриминатора.\n",
    "\n",
    "**Unsupervised NMT**. Идея в том, чтобы обучить переводчик вообще без параллельных данных. Это нафиг никому не нужно (хороших параллельных данных для перевода на самом деле в избытке), но весьма впечетляет, что такое  вообще возможно. Обучаются по два denoising autoencoder и навешивается adversarial loss на скрытое состояние (это мотивирует распределения быть похожими). Так как скрытые состояния почти одни и те же, можно попробовать просто поменять декодеры местами, то есть прогнать предложение на языке А со своим энкодером, но декодером из нужного языка.\n",
    "\n",
    "<фотка с Путиным>\n",
    "\n",
    "**DissoNet**. Помимо дискриминатора, здесь есть ещё и мотиватор. На самом деле, GAN-ы для постедовательных данных работают не очень хорошо — это связано с их дискретностью. К тому же, тут не очень хватает метрик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4gzwFpIYh03"
   },
   "source": [
    "# Нерешённые (нерешаемые?) проблемы\n",
    "\n",
    "* Формулировать то, что мы хотим через adversarial loss это лучше, чем «сделай заебись», но все равно непонятно, как этот adversarial loss мерить. Оказывается, kld имеет огромные недостататки.\n",
    "* Оно долго сходится, а также это никак не померить.\n",
    "* До того, как условились мерить всё через inception score, вся эта фигня была чисто субъективной. В текстах inception score ещё не придумали как сделать, и  поэтому люди там пока тоже ходят кругами. Когда нет метрики, процесс превращается в выбор самых красивых сгенерированных примеров. Inception score ещё зависит от того, насколько похожие архитектуры были использованы для дискриминатора — понятно, что ResNet проще обмануть, если дискриминатор тоже был резнетом."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4_gans.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
