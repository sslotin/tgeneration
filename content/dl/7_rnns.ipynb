{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7_rnns.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"UMsmIZeRGoEV","colab_type":"text"},"cell_type":"markdown","source":["# Последовательные данные"]},{"metadata":{"id":"KRPQpLePGoEX","colab_type":"text"},"cell_type":"markdown","source":["Для анализа последовательных данных — звука, музыки, текста, температуры в Мюнхене, изменения цены биткоина, спортивной статистики, шахматных ходов, состояний игры в Доте — используются свои архитектуры, использующие «память» для обработки данных произвольной длины."]},{"metadata":{"id":"DbP9r3D8GoEa","colab_type":"text"},"cell_type":"markdown","source":["## Рекуррентные сети\n","\n"]},{"metadata":{"id":"sjOx2H8ZGoEd","colab_type":"text"},"cell_type":"markdown","source":["Пусть у нас есть какая-нибудь функция от двух векторных аргументов $f(x, h)$ (нейросеть с trainable параметрами — тоже как бы функция) и какая-нибудь последовательость входных данных $\\{x_1, x_2, \\ldots, x_n\\}$.\n","\n","Получим последовательность $\\{h_1, h_2, \\ldots, h_n\\}$ по следующему правилу: $ h_t = f(x_i, h_{t-1}) $ ($h_0$ предполагаем чем-нибудь изначально инициализированным). Все осталньые $h_i$ будут потом использоваться для чего-то полезного."]},{"metadata":{"id":"tjs7DzHnGoEf","colab_type":"text"},"cell_type":"markdown","source":["Когда мы это всё развернем, на самом деле получится обычный статический вычислительный граф, выходом которого будет $n$ скрытых состояний."]},{"metadata":{"id":"Wu3tGzC0GoEh","colab_type":"text"},"cell_type":"markdown","source":["![RNN](https://i.stack.imgur.com/hzZ4m.png)"]},{"metadata":{"id":"SAZ3dYUBGoEj","colab_type":"text"},"cell_type":"markdown","source":["Подобные архитектуры и называют рекуррентными сетями."]},{"metadata":{"id":"7ZFKYGWqGoEk","colab_type":"text"},"cell_type":"markdown","source":["# «Затухающий градиент»"]},{"metadata":{"id":"NtOre8pWGoEm","colab_type":"text"},"cell_type":"markdown","source":["**В чём проблема**. Мы знаем, что глубокие сети очень трудно обучать. Рекуррентная сеть по сути не отличается от очень глубокой статичной сети, данные которой вставляются в разные уровни глубины. С такой архитектурой будет очень трудно уловить связь, например, между данными на начале последовательности и целевой функцией."]},{"metadata":{"id":"8BCt-sTMGoEn","colab_type":"text"},"cell_type":"markdown","source":["**LSTM**. Чтобы с этим побороться, придумали различные механизмы памяти. \n","\n","Представьте конвейерную ленту, которая движется вдоль наших последовательных данных. Информация с данных может запрыгивать на ленту, проезжать вперед и спрыгивать оттуда, когда она понадобится. LSTM (long-short term memory) — это тот блок, который решает, какой информации нужно запрыгнуть. Он позволяет сохранять информацию для более позднего времени, когда она понадобится.\n","\n","Он состоит из нескольких «гейтов», каждый из которых представляет собой trainable матрицу, которые решают, что можно забыть, что можно добавить, и что сейчас в данный момент важно от входных данных. Эти гейты считают маски — вектора после softmax — на которые домножаются входные данные.\n","\n","![lstm](images/lstm.png)"]},{"metadata":{"id":"PT_2G9inGoEo","colab_type":"text"},"cell_type":"markdown","source":["Эту LSTM-ячейку мы просто будем использовать в качестве $f$. Суть не изменилась: граф также разворачивается в статический, только более сложный."]},{"metadata":{"id":"A5LRoxoQGoEp","colab_type":"text"},"cell_type":"markdown","source":["![LSTM](https://cdn-images-1.medium.com/max/2000/1*S0Y1A3KXYO7_eSug_KsK-Q.png)"]},{"metadata":{"id":"szNQUN4rGoEq","colab_type":"text"},"cell_type":"markdown","source":["# Эмбеддинги"]},{"metadata":{"id":"bDMlYbqCGoEr","colab_type":"text"},"cell_type":"markdown","source":["Рассмотрим задачу классификации текстов по их темам (тематическое моделирование).\n","\n","Нейросети не берут на вход сырые текстовые данные, а работают с векторами. Как правило, текст разделяют (*токенизируют*) на мелкие куски (буквы, слова, отдельные слоги), а дальше каждый токен заменяется на one-hot вектор размерности словаря.\n","\n","Но что будет, если помножить one-hot вектор на матрицу? Получится просто какая-то строка матрицы. Вместо этой операции можно сразу вставить строку, соответствующую единичке. Эта концепция называется embedding — теперь каждому токену ассоциирован его вектор.\n","\n","**Word2vec**. У этих векторов есть смысл и много применений. В них даже работает всякая алгебра типа «король - мужчина + женщина = королева». Синонимы должны иметь очень близкие вектора.\n","\n","![word2vec](images/word2vec.png)\n","\n","Впрочем, геометрическая интерпретация пока не нашла особых применений.\n","\n","Зацените ещё эту игру: https://research.google.com/semantris"]},{"metadata":{"id":"PDqD81XNGoEt","colab_type":"text"},"cell_type":"markdown","source":["word2vec, glove, fasttext — это все эмбеддинги, только посчитанные разными алгоритмами на разных задачах."]},{"metadata":{"id":"dM5qe_BqGoEu","colab_type":"text"},"cell_type":"markdown","source":["# Пишем код\n","\n","Типичный пайплайн в NLP такой:\n","\n","* Токенизировать данные\n","* Сконвертировать в вектора\n","* Написать модель и зафитить\n","* Сконвертировать обратно (если мы генерируем тоже текст)\n","\n","Только третий пункт относится к DL, остальное тоже нужно сделать, но не сейчас. В примере данные уже будут токенизированы за нас."]},{"metadata":{"id":"Vg-zYpKJGoEv","colab_type":"text"},"cell_type":"markdown","source":["Есть такой сайт, как IMDB — пиндосский кинопоиск. На нём есть отзывы к фильмам, которые бывают положительные и отрицательные. Мы хотим научиться из классифицировать на эти два класса, не зная лейбл, а только сам текст отзыва."]},{"metadata":{"id":"4vdeSleqGoEv","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.preprocessing import sequence\n","from keras.datasets import imdb\n","\n","# нужно как-то ограничить число токенов\n","# редкие токены будут объединены в один токен <unk>\n","vocab_size = 10000\n","embedding_dim = 50 # вектор этого размера будет ассоциирован с каждым \n","\n","(X, y), _ = imdb.load_data(num_words=vocab_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x-o51nX2GoEz","colab_type":"text"},"cell_type":"markdown","source":["Камень в сторону фреймворков, строящих статический вычислительный граф (Keras относится к ним): оно на практике реализовано так, как на первой картинке: просто все разворачивается в один длинный граф с расшаренными весами. Это дает такое ограничение: внутри батча все данные должны быть одной длины. Даже если у нас есть очень короткие предложения, их нужно дополнить специальными токенами до некоторой константы maxlen. Многие операции будут считаться впустую, но ничего с этим нам пока не поделать."]},{"metadata":{"id":"halsRr0IGoE0","colab_type":"text"},"cell_type":"markdown","source":["Подберем правильный maxlen:"]},{"metadata":{"id":"TI2I_cDmGoE1","colab_type":"code","colab":{},"outputId":"f6cbfd04-4529-4a66-d14c-3df673eec8c8"},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","sns.set()\n","\n","lens = [len(x) for x in X]\n","sns.distplot(lens)\n","print(np.percentile(lens, 90))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["467.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<matplotlib.figure.Figure at 0x7f8de97bfcf8>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"mPb2iwpBGoE8","colab_type":"text"},"cell_type":"markdown","source":["Можем выбрать в качестве этого параметра что-то около 500. Это покроет более 90% примеров, и это хороший trade-off между потерей информации и скоростью работы."]},{"metadata":{"id":"C_qVDfWNGoE8","colab_type":"code","colab":{}},"cell_type":"code","source":["maxlen = 500\n","X = sequence.pad_sequences(X, maxlen=maxlen)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SygZ2rJAGoE-","colab_type":"code","colab":{},"outputId":"d4eee46a-b9e8-452c-fd1e-cbed9a8a3367"},"cell_type":"code","source":["from keras.layers import LSTM, Dense, Embedding\n","from keras.models import Sequential\n","\n","RNN = Sequential([\n","    Embedding(vocab_size, embedding_dim), # эта шняга тупо переводит int-ы соответствующие вектора\n","    LSTM(embedding_dim), # lstm, примененный к векторизованной последовательности\n","    # вернет свое итоговое состояние\n","    Dense(1, activation='sigmoid')\n","])\n","\n","RNN.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, None, 50)          500000    \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 50)                20200     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 51        \n","=================================================================\n","Total params: 520,251\n","Trainable params: 520,251\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"vqe77xe2GoFE","colab_type":"code","colab":{},"outputId":"f723e0c7-5614-475e-9b3f-b93a5fa3830b"},"cell_type":"code","source":["RNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n","history = RNN.fit(X, y, epochs=5, validation_split=0.1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 22500 samples, validate on 2500 samples\n","Epoch 1/5\n","22500/22500 [==============================] - 1585s - loss: 0.4982 - acc: 0.7549 - val_loss: 0.3985 - val_acc: 0.8244\n","Epoch 2/5\n","22500/22500 [==============================] - 1713s - loss: 0.2828 - acc: 0.8903 - val_loss: 0.3320 - val_acc: 0.8768\n","Epoch 3/5\n","22500/22500 [==============================] - 286s - loss: 0.2364 - acc: 0.9079 - val_loss: 0.3665 - val_acc: 0.8424\n","Epoch 4/5\n","22500/22500 [==============================] - 327s - loss: 0.2279 - acc: 0.9088 - val_loss: 0.4192 - val_acc: 0.8672\n","Epoch 5/5\n","22500/22500 [==============================] - 368s - loss: 0.1400 - acc: 0.9511 - val_loss: 0.4796 - val_acc: 0.7960\n"],"name":"stdout"}]},{"metadata":{"id":"Pm7FHW1HGoFI","colab_type":"text"},"cell_type":"markdown","source":["# Transfer Learning"]},{"metadata":{"id":"S4h0YXSnGoFJ","colab_type":"text"},"cell_type":"markdown","source":["Если вы поизучали то, что вернул .summary(), то могли заметить, что большинство параметров — сами embedding-и, и в основном на их обучение уходит время.\n","\n","Так же как и с CNN, где мы «крали» веса с начальных слоев, здесь мы можем сделать то же самое, украв embedding-и у более основательно подошедших к этому людей."]},{"metadata":{"id":"Lcl9i1CgGoFJ","colab_type":"text"},"cell_type":"markdown","source":["Обычно эти шняги распространяют в формате «слово в unicode и 300 флоатов через пробел»."]},{"metadata":{"id":"1QIzZ2ToGoFK","colab_type":"code","colab":{}},"cell_type":"code","source":["with open('glove.vec') as file:\n","    for line in file:\n","        l = line.split()\n","        word = l[0]\n","        vec = np.array([float(x) for x in l[1:]])\n","        embeddings += [vec]\n","embeddings = np.stack(embeddings)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6Q196Wb6GoFM","colab_type":"text"},"cell_type":"markdown","source":["Теперь можно указать для слоя Embedding, откуда брать веса, через `weights=[embeddings]` и зафризить через trainable=False. Весь Transfer Learning делается примерно так. Правда, иногда не размораживают после какой-то эпохи."]},{"metadata":{"id":"ozNq4xC9GoFM","colab_type":"text"},"cell_type":"markdown","source":["# Свёрточные сети для последовательностей"]},{"metadata":{"id":"tzzQaw1zGoFN","colab_type":"text"},"cell_type":"markdown","source":["Как бы мы обрабатываем последовательности произвольной длины, но и как бы нет. Можно фиксировать длину предложения и попробовать уже известные архитектуры.\n","\n","Для некоторых задач — например, распознования речи, — свёрточные сети могут быть даже лучше. Загуглите WaveNet."]},{"metadata":{"id":"7f1YicSjGoFO","colab_type":"code","colab":{},"outputId":"3ef7f44d-c702-4b0d-8285-63c5b81e008c"},"cell_type":"code","source":["from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout\n","\n","TextCNN = Sequential([\n","    Embedding(vocab_size, embedding_dim, weights=[embeddings], input_length=maxlen, trainable=False),\n","    Conv1D(32, 7, activation='relu', padding='same'),\n","    MaxPooling1D(2),\n","    Conv1D(64, 7, activation='relu', padding='same'),\n","    GlobalMaxPooling1D(),\n","    Dropout(0.5),\n","    Dense(32, activation='relu'),\n","    Dense(1, activation='sigmoid'),\n","])\n","\n","TextCNN.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 500, 50)           500000    \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 500, 32)           11232     \n","_________________________________________________________________\n","max_pooling1d_1 (MaxPooling1 (None, 250, 32)           0         \n","_________________________________________________________________\n","conv1d_2 (Conv1D)            (None, 250, 64)           14400     \n","_________________________________________________________________\n","global_max_pooling1d_1 (Glob (None, 64)                0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 32)                2080      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 33        \n","=================================================================\n","Total params: 527,745\n","Trainable params: 27,745\n","Non-trainable params: 500,000\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"rfzGtTV7GoFS","colab_type":"text"},"cell_type":"markdown","source":["# Как правильно делать токенизацию"]},{"metadata":{"id":"A1UsX-aWGoFT","colab_type":"text"},"cell_type":"markdown","source":["Токенизация — это всегда головная боль. Её кодить не сложно, но муторно, и поэтому было написано дофига библиотек, которые это делают. В частности, какие-то токенизаторы есть и в Keras."]},{"metadata":{"id":"sX3wssx_GoFU","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer(num_words=10)\n","tokenizer.fit_on_texts('гыгыгы')\n","tokenized = tokenizer.texts_to_sequences('азаза')"],"execution_count":0,"outputs":[]}]}